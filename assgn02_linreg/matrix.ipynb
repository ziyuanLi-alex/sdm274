{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "# matplotlib.use('TkAgg') # 在Ubuntu上执行代码，如果想从窗口中弹出图形，需要加上这一行\n",
    "\n",
    "# 生成数据，使用线性模型 y = w * x + b + noise，指定seed，保证每次运行代码生成的数据一致\n",
    "# np.random.seed(42)\n",
    "X_train = np.arange(100).reshape(100, 1)\n",
    "a, b = 1, 10\n",
    "y_train = a * X_train + b + np.random.normal(0, 5, size=X_train.shape)\n",
    "y_train = y_train.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color='blue', label='Data points')\n",
    "plt.xlabel('X_train')\n",
    "plt.ylabel('y_train')\n",
    "plt.title('Scatter plot of the generated data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "\n",
    "    def __init__(self, n_feature = 1, epochs = 100, lr = 1e-5):\n",
    "        self.n_feature = n_feature\n",
    "        self.epochs = epochs\n",
    "        self.W = np.random.random(n_feature + 1) * 0.05\n",
    "        self.loss = []\n",
    "        self.epoch_loss = []\n",
    "        self.lr = lr\n",
    "\n",
    "    def _loss(self, y, y_pred):\n",
    "        return np.sum((y - y_pred) ** 2) / y.size\n",
    "\n",
    "    def gradient(self, X, y, y_pred):\n",
    "        return (y_pred - y) @ X / y.size\n",
    "\n",
    "    def _preprocess(self, X):\n",
    "        m, n = X.shape\n",
    "        X_ = np.empty([m, n + 1])\n",
    "        X_[:, 0] = 1\n",
    "        X_[:, 1:] = X\n",
    "        return X_\n",
    "\n",
    "    def _predict(self, X):\n",
    "        return X @ self.W\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_ = self._preprocess(X)\n",
    "        return self._predict(X_)\n",
    "    \n",
    "    def BGD(self, X, y):\n",
    "        X_ = self._preprocess(X)\n",
    "        self.loss.append(self._loss(y, self._predict(X_)))\n",
    "        self.epoch_loss.append(self._loss(y, self._predict(X_)))\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            y_pred = self._predict(X_)\n",
    "            self.W -= self.lr * self.gradient(X_, y, y_pred) # gradient descent\n",
    "            self.loss.append(self._loss(y, y_pred))\n",
    "            self.epoch_loss.append(self._loss(y, y_pred))\n",
    "    \n",
    "    def SGD(self, X, y):\n",
    "        X_ = self._preprocess(X)\n",
    "        self.loss.append(self._loss(y, self._predict(X_)))\n",
    "        self.epoch_loss.append(self._loss(y, self._predict(X_)))\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            shuffle_index = np.random.permutation(X_.shape[0])\n",
    "            X_ = X_[shuffle_index]\n",
    "            y = y[shuffle_index]\n",
    "            for i in range(len(y)):\n",
    "                xi = X_[i].reshape(1, -1)  # Select a single data point and reshape to match input dimension\n",
    "                yi = y[i].reshape(-1)       # Select the corresponding target value and reshape to match output dimension\n",
    "                y_pred = self._predict(xi)\n",
    "                self.W -= self.lr * self.gradient(xi, yi, y_pred).flatten()  # Update weights based on single data point\n",
    "                self.loss.append(self._loss(yi, y_pred))\n",
    "            \n",
    "            y_pred_epoch = self._predict(X_)\n",
    "            self.epoch_loss.append(self._loss(y, y_pred_epoch))\n",
    "            \n",
    "\n",
    "    def MBGD(self, X, y, batch_size):\n",
    "        X_ = self._preprocess(X)\n",
    "        num_batches = len(y) // batch_size\n",
    "        self.loss.append(self._loss(y, self._predict(X_)))\n",
    "        self.epoch_loss.append(self._loss(y, self._predict(X_)))\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            shuffle_index = np.random.permutation(X_.shape[0])\n",
    "            X_ = X_[shuffle_index]\n",
    "            y = y[shuffle_index]\n",
    "            for batch in range(num_batches):\n",
    "                start = batch * batch_size\n",
    "                end = start + batch_size\n",
    "                xi = X_[start:end]  # Select a batch of data points\n",
    "                yi = y[start:end]   # Select the corresponding target values\n",
    "                y_pred = self._predict(xi)\n",
    "                self.W -= self.lr * self.gradient(xi, yi, y_pred)  # Update weights based on the batch\n",
    "                self.loss.append(self._loss(yi, y_pred))\n",
    "\n",
    "            # Compute loss for the entire dataset\n",
    "            y_pred_epoch = self._predict(X_)\n",
    "            self.epoch_loss.append(self._loss(y, y_pred_epoch))\n",
    "\n",
    "    def minmax_norm(self, X):\n",
    "        return (X - X.min()) / (X.max() - X.min())\n",
    "\n",
    "    def mean_norm(self, X):\n",
    "        return (X - X.mean()) / (X.max() - X.min())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_test = LinearRegression()\n",
    "X_minmax = norm_test.minmax_norm(X_train)\n",
    "X_mean = norm_test.mean_norm(X_train)\n",
    "\n",
    "plt.scatter(X_mean, y_train, color='blue', label='Data points')\n",
    "plt.scatter(X_minmax, y_train, color='red', label='Data points')\n",
    "plt.axhline(y=0, color='black', linewidth=0.5)\n",
    "plt.axvline(x=0, color='black', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的代码用来准备归一化后的数据。plt可以直观地展示归一化的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_lreg = LinearRegression()\n",
    "gd_lreg.BGD(X_train, y_train)\n",
    "\n",
    "sgd_lreg = LinearRegression()\n",
    "sgd_lreg.SGD(X_train, y_train)\n",
    "\n",
    "mbgd_lreg = LinearRegression()\n",
    "mbgd_lreg.MBGD(X_train, y_train, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gd_lreg.epoch_loss)\n",
    "plt.plot(sgd_lreg.epoch_loss)\n",
    "plt.plot(mbgd_lreg.epoch_loss)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['BGD', 'SGD', 'MBGD'])\n",
    "plt.title('Loss curve of the linear regression model, measuring by epochs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(gd_lreg.loss[:100])\n",
    "plt.plot(sgd_lreg.loss[:100])\n",
    "plt.plot(mbgd_lreg.loss[:100])\n",
    "plt.xlabel('GD steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['BGD', 'SGD', 'MBGD'])\n",
    "plt.title('Loss curve of the linear regression model, measuring by times of calculation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mbgd_lreg = LinearRegression()\n",
    "# mbgd_lreg.MBGD(X_train, y_train, 10)\n",
    "\n",
    "minmax_mbgd_lreg = LinearRegression()\n",
    "# minmax_mbgd_lreg.lr = 1e-6\n",
    "minmax_mbgd_lreg.MBGD(X_minmax, y_train, 10)\n",
    "\n",
    "mean_mbgd_lreg = LinearRegression()\n",
    "# minmax_mbgd_lreg.lr = 1e-6\n",
    "mean_mbgd_lreg.MBGD(X_mean, y_train, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(mean_mbgd_lreg.loss[:80])\n",
    "plt.plot(minmax_mbgd_lreg.loss[:80])\n",
    "plt.plot(mbgd_lreg.loss[:80])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Mean normalization', 'Min-max normalization', 'No normalization'])\n",
    "plt.title('Loss curve of the linear regression model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color='blue', label='Data points')\n",
    "plt.plot(X_train, gd_lreg.predict(X_train), color='red', label='Fitted line')\n",
    "plt.plot(X_train, a * X_train + b, color='green', label='True line')\n",
    "plt.xlabel('X_train')\n",
    "plt.ylabel('y_train')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
